<!doctype html><html lang=zh-tw itemscope itemtype=http://schema.org/WebPage><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1"><title>PyTorch RNN Tutorial - eri24816's blog</title>
<meta name=description content="This tutorial will demonstrate how to build and train a simple RNN model with PyTorch.
Concepts
What can an RNN do?
Given an input sequence $x=[x_1,x_2,\cdots,x_{n}]$, an RNN can generate a corresponding output sequence $\hat y=[\hat y_1,\hat y_2,\cdots,\hat y_{n}]$
successively. The strength of RNN is that it can &ldquo;remember&rdquo; its previosly seen input elements. When calculating $\hat y_i$, the model can access not only $x_i$ but also the information from $x_0$ to $x_{i-1}$, via its hidden state, $h_{i-1}$."><script type=application/ld+json>{"@context":"http://schema.org","@type":"WebSite","name":"eri24816\u0027s blog","url":"https:\/\/eri24816.tw\/"}</script><script type=application/ld+json>{"@context":"http://schema.org","@type":"Organization","name":"","url":"https:\/\/eri24816.tw\/"}</script><script type=application/ld+json>{"@context":"http://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"item":{"@id":"https:\/\/eri24816.tw\/","name":"home"}},{"@type":"ListItem","position":3,"item":{"@id":"https:\/\/eri24816.tw\/post\/rnn_tutorial\/","name":"Py torch rnn tutorial"}}]}</script><script type=application/ld+json>{"@context":"http://schema.org","@type":"Article","author":{"name":""},"headline":"PyTorch RNN Tutorial","description":"This tutorial will demonstrate how to build and train a simple RNN model with PyTorch.\nConcepts What can an RNN do? Given an input sequence $x=[x_1,x_2,\\cdots,x_{n}]$, an RNN can generate a corresponding output sequence $\\hat y=[\\hat y_1,\\hat y_2,\\cdots,\\hat y_{n}]$ successively. The strength of RNN is that it can \u0026ldquo;remember\u0026rdquo; its previosly seen input elements. When calculating $\\hat y_i$, the model can access not only $x_i$ but also the information from $x_0$ to $x_{i-1}$, via its hidden state, $h_{i-1}$.\n","inLanguage":"zh-tw","wordCount":451,"datePublished":"2022-03-09T12:54:18","dateModified":"2022-03-09T12:54:18","image":"https:\/\/eri24816.tw\/","keywords":["Python, torch"],"mainEntityOfPage":"https:\/\/eri24816.tw\/post\/rnn_tutorial\/","publisher":{"@type":"Organization","name":"https:\/\/eri24816.tw\/","logo":{"@type":"ImageObject","url":"https:\/\/eri24816.tw\/","height":60,"width":60}}}</script><meta property="og:title" content="PyTorch RNN Tutorial"><meta property="og:description" content="This tutorial will demonstrate how to build and train a simple RNN model with PyTorch.
Concepts
What can an RNN do?
Given an input sequence $x=[x_1,x_2,\cdots,x_{n}]$, an RNN can generate a corresponding output sequence $\hat y=[\hat y_1,\hat y_2,\cdots,\hat y_{n}]$
successively. The strength of RNN is that it can &ldquo;remember&rdquo; its previosly seen input elements. When calculating $\hat y_i$, the model can access not only $x_i$ but also the information from $x_0$ to $x_{i-1}$, via its hidden state, $h_{i-1}$."><meta property="og:image" content="https://i.imgur.com/X6kty5v.jpg"><meta property="og:url" content="https://eri24816.tw/post/rnn_tutorial/"><meta property="og:type" content="website"><meta property="og:site_name" content="eri24816's blog"><link rel=apple-touch-icon sizes=180x180 href=https://eri24816.tw/favicon/apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=https://eri24816.tw/favicon/favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=https://eri24816.tw/favicon/favicon-16x16.png><meta name=generator content="Hugo 0.138.0"><link rel=alternate href=https://eri24816.tw/index.xml type=application/rss+xml title="eri24816's blog"><script src=https://eri24816.tw/js/dark-mode.js></script><link rel=stylesheet href=/style.min.css><link rel=stylesheet href=https://eri24816.tw/custom.css><script>MathJax={tex:{inlineMath:[["$","$"],["\\(","\\)"]],displayMath:[["$$","$$"],["\\[","\\]"]],processEscapes:!0,processEnvironments:!0},options:{skipHtmlTags:["script","noscript","style","textarea","pre"]}},window.addEventListener("load",e=>{document.querySelectorAll("mjx-container").forEach(function(e){e.parentElement.classList+="has-jax"})})</script><script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script><script type=text/javascript id=MathJax-script async src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js></script><link rel=preconnect href=https://fonts.googleapis.com><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link href="https://fonts.googleapis.com/css2?family=Raleway:ital,wght@0,100..900;1,100..900&display=swap" rel=stylesheet><link href=/vendor/glightbox/css/glightbox.min.css rel=stylesheet><script src=https://eri24816.tw/vendor/glightbox/js/glightbox.min.js></script></head><body><img src=https://i.imgur.com/pBOqZZb.png alt=bg class=bg-img>
<script>document.addEventListener("DOMContentLoaded",function(){const e=document.querySelector(".bg-img"),s=document.querySelector(".index"),t=document.querySelector(".index-container");function n(){const n=window.pageYOffset||document.documentElement.scrollTop,i=n/300,a=Math.min(2,n/400);let o;s?o=Math.max(.2,.8-n/300):o=.2,t&&(t.style.opacity=i),e&&(e.style.filter=`brightness(${o})`,e.style.top=`${.7*n}px`)}n(),window.addEventListener("scroll",n)})</script><div class="container fixed-top mw-100"><div class="row justify-content-center"><div class="col-sm-12 col-md-12 col-lg-10 col-xl-10"><nav class="navbar navbar-expand-lg navbar-light fixed-top p-0"><div class=container><a class="navbar-brand fw-bold" href=https://eri24816.tw/>eri24816's blog</a>
<button class=navbar-toggler type=button data-bs-toggle=collapse data-bs-target=#navbarNav aria-controls=navbarNav aria-expanded=false aria-label="Toggle navigation">
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse justify-content-end" id=navbarNav><ul class="navbar-nav mb-2 mb-lg-0 align-items-baseline"><li class="nav-item dropdown"><button class="p-1 rounded dropdown-toggle border-gray-500" data-bs-toggle=dropdown aria-expanded=false>
zh-tw</button><ul class=dropdown-menu><li><a class="dropdown-item active" aria-current=page href=https://eri24816.tw/post/rnn_tutorial/>繁體中文</a></li></ul></li><li class="nav-item nav-link"><a id=dark-mode-toggle class="bi bi-moon-stars" role=button></a></li></ul></div></div></nav></div></div></div><header class=header-section><div class="intro-header no-img mt-10"><div class=container><div class="row justify-content-center"><div class="col-sm-12 col-md-12 col-lg-8 col-xl-8"><div class="col-sm-12 col-md-12 col-lg-12 col-xl-12"><div class=post-heading><h1 class="fw-semibold display-5 lh-1 mb-3">PyTorch RNN Tutorial</h1><span class=post-meta><div class="row post-meta text-muted"><div class="col-sm-12 col-md-6 px-0">&nbsp; March 9, 2022</div><div class="col-sm-12 col-md-6 text-sm-start text-md-end px-0"></div></div></span></div></div></div></div></div></div></header><div class=container role=main><div class=row><div class="col-lg-8 offset-lg-2 col-md-10 offset-md-1 pt-4"><article role=main class=blog-post><p>This tutorial will demonstrate how to build and train a simple RNN model with PyTorch.</p><h2 id=concepts>Concepts</h2><h3 id=what-can-an-rnn-do>What can an RNN do?</h3><p>Given an input sequence $x=[x_1,x_2,\cdots,x_{n}]$, an RNN can generate a corresponding output sequence $\hat y=[\hat y_1,\hat y_2,\cdots,\hat y_{n}]$
successively. The strength of RNN is that it can &ldquo;remember&rdquo; its previosly seen input elements. When calculating $\hat y_i$, the model can access not only $x_i$ but also the information from $x_0$ to $x_{i-1}$, via its hidden state, $h_{i-1}$.</p><p><img alt=Image src=https://i.imgur.com/lw62OZL.png#center></p><h3 id=autoregressive-model>Autoregressive model</h3><p>Given the characteristics of an RNN, we can make it do something cool &ndash; predicting a sequence.</p><p>Imagine now we have a initial sequence [1,2,3,4,5] and feed it into an RNN. If the model is good at predicting linear sequences, it will predict some number near 6 as the next number, let&rsquo;s say 6.05.</p><p><img alt=Image src=https://i.imgur.com/cCr0pSK.png></p><p>Then we put the 6.05 back to the sequence, make it [1,2,3,4,5,6.05], and feed it into the model again. This time, the model says 7.02, so the sequence becomes [1,2,3,4,5,6.05,7.02]. As we repeat this process, the model can eventually generate a long sequence by itself.</p><p><img alt=Image src=https://i.imgur.com/UhcKdwA.png></p><p>To be precise, when training the model, we want it predict $x_{i+1}$ after seeing the input $[x_1, x_2, \cdots,x_{i}]$. That is, the difference between its output, $\hat y_i$, and the target output, $x_{i+1}$, should be minimized.</p><p><img alt=Image src=https://i.imgur.com/jChTnLU.png#center></p><p>We can define sequence $y =[ y_1, y_2,\cdots, y_{n}]$ as the target output, which $y_i = x_{i+1}$.</p><p>Thus, the loss function is the mean square error between $\hat y$ and $y$:</p><p>$$ \frac{1}{n}\sum_{i= 1}^{n}{(\hat y_i-x_{i+1})^2} = \frac{1}{n}\sum_{i= 1}^{n}{(\hat y_i-y_i)^2} = MSE(\hat y,y)$$.</p><h2 id=implementation>Implementation</h2><h3 id=1-import>1. Import</h3><p>Import the modules we will need.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>import</span> numpy <span style=color:#66d9ef>as</span> np
</span></span><span style=display:flex><span><span style=color:#f92672>import</span> torch
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> torch <span style=color:#f92672>import</span> nn
</span></span><span style=display:flex><span><span style=color:#f92672>import</span> matplotlib.pyplot <span style=color:#66d9ef>as</span> plt
</span></span></code></pre></div><h3 id=2-prepare-the-training-data>2. Prepare the training data</h3><p>First, we need the training data.
Here we generate a sine wave of $\sin(t)$, from $t=0$ to $t=80$, and sample peirod $=0.2$. Then a little noise is added to simulate sampling error.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>data <span style=color:#f92672>=</span> np<span style=color:#f92672>.</span>sin(np<span style=color:#f92672>.</span>arange(<span style=color:#ae81ff>0</span>,<span style=color:#ae81ff>80</span>,<span style=color:#ae81ff>0.2</span>))
</span></span><span style=display:flex><span>data <span style=color:#f92672>+=</span> (np<span style=color:#f92672>.</span>random<span style=color:#f92672>.</span>random(data<span style=color:#f92672>.</span>shape)<span style=color:#f92672>-</span><span style=color:#ae81ff>0.5</span>)<span style=color:#f92672>*</span><span style=color:#ae81ff>0.2</span>
</span></span><span style=display:flex><span>plt<span style=color:#f92672>.</span>plot(data)
</span></span></code></pre></div><p><img alt=Image src=https://i.imgur.com/07PP9iu.jpg#centers></p><p>By default, an RNN module require its input tensor to have the shape $[ Time, Batch, Feature ]$. To keep it simple, we can just set the
batch size and feature num to 1. So we have to expand the original data of size $[400]$ to $[ 400, 1,1 ]$ by doing unsqueeze(-1) twice.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>print(data<span style=color:#f92672>.</span>shape) <span style=color:#75715e>#(400,)</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># convert data into a torch tensor and expand the dimension of its shape</span>
</span></span><span style=display:flex><span>data <span style=color:#f92672>=</span> torch<span style=color:#f92672>.</span>tensor(data, dtype <span style=color:#f92672>=</span> torch<span style=color:#f92672>.</span>float)<span style=color:#f92672>.</span>unsqueeze(<span style=color:#f92672>-</span><span style=color:#ae81ff>1</span>)<span style=color:#f92672>.</span>unsqueeze(<span style=color:#f92672>-</span><span style=color:#ae81ff>1</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>print(data<span style=color:#f92672>.</span>shape) <span style=color:#75715e># torch.Size([400, 1, 1])</span>
</span></span></code></pre></div><p>Get x and y that satisfy $y_i = x_{i+1}$.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#75715e>#input sequence</span>
</span></span><span style=display:flex><span>x <span style=color:#f92672>=</span> data[:<span style=color:#f92672>-</span><span style=color:#ae81ff>1</span>]
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># target output sequence</span>
</span></span><span style=display:flex><span>y <span style=color:#f92672>=</span> data[<span style=color:#ae81ff>1</span>:]
</span></span></code></pre></div><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#66d9ef>class</span> <span style=color:#a6e22e>SimpleRNN</span>(nn<span style=color:#f92672>.</span>Module):
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>def</span> __init__(self):
</span></span><span style=display:flex><span>        super()<span style=color:#f92672>.</span>__init__()
</span></span><span style=display:flex><span>        self<span style=color:#f92672>.</span>rnn <span style=color:#f92672>=</span> nn<span style=color:#f92672>.</span>RNN(<span style=color:#ae81ff>1</span>,<span style=color:#ae81ff>12</span>)
</span></span><span style=display:flex><span>        self<span style=color:#f92672>.</span>linear <span style=color:#f92672>=</span> nn<span style=color:#f92672>.</span>Linear(<span style=color:#ae81ff>12</span>,<span style=color:#ae81ff>1</span>)
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>def</span> <span style=color:#a6e22e>forward</span>(self, x, h_0 <span style=color:#f92672>=</span> <span style=color:#66d9ef>None</span>):
</span></span><span style=display:flex><span>        rnn_out, h_n <span style=color:#f92672>=</span> self<span style=color:#f92672>.</span>rnn(x, h_0)
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>return</span> self<span style=color:#f92672>.</span>linear(rnn_out), h_n
</span></span></code></pre></div></article></div></div><div class=row><div class="col-lg-8 offset-lg-2 col-md-10 offset-md-1"><hr class=m-0></div><div class="col-lg-8 offset-lg-2 col-md-10 offset-md-1 pt-2"><div class=blog-tags><a href=https://eri24816.tw/tags/python/>Python</a>
<a href=https://eri24816.tw/tags/torch/>torch</a></div></div><div class="col-lg-8 offset-lg-2 col-md-10 offset-md-1 pt-4"></div><div class="col-lg-8 offset-lg-2 col-md-12 offset-md-1 pt-4"><ul class="list-group list-group-horizontal" style=flex-direction:row><li class="list-group-item b-0 p-0"><a type=button class="btn btn-dark" role=button href=https://eri24816.tw/post/cat_simulator/ data-toggle=tooltip data-placement=top title="Cat simulator">&larr;
上一篇</a></li><li class="list-group-item ms-auto b-0 p-0"><a type=button class="btn btn-dark" role=button href=https://eri24816.tw/post/reverb_plugin/ data-toggle=tooltip data-placement=top title="Reverb plugin">下一篇
&rarr;</a></li></ul></div><div class="col-lg-8 offset-lg-2 col-md-10 offset-md-1 pt-4"></div></div></div><div></div><footer><div class=container><div class=row><div class=col-md-12><ul class="list-inline list-group list-group-horizontal text-center footer-links d-flex justify-content-center flex-row"></ul></div></div><div class=row><div class=col-md-12><p class="credits copyright text-muted">&nbsp;&bull;&nbsp;&copy;
2024
&nbsp;&bull;&nbsp;
<a href=https://eri24816.tw/>eri24816's blog</a></p><p class="credits theme-by text-muted">Powered by <a href=https://gohugo.io>Hugo</a> & <a href=https://github.com/binokochumolvarghese/lightbi-hugo>Lightbi.</a>&nbsp; Made with ❤ by <a href=https://binovarghese.com>Bino</a></p></div></div></div></footer><script src=https://cdn.jsdelivr.net/npm/bootstrap@5.3.2/dist/js/bootstrap.bundle.min.js integrity=sha384-C6RzsynM9kWDrMNeT87bh95OGNyZPhcTNXj1NW7RuBCsyN/o0jlpcV8Qyq46cDfL crossorigin=anonymous></script></body></html>