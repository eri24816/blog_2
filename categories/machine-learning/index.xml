<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Machine Learning on Eri24816's blog</title><link>https://example.org/categories/machine-learning/</link><description>Recent content in Machine Learning on Eri24816's blog</description><generator>Hugo -- gohugo.io</generator><language>zh-tw</language><lastBuildDate>Wed, 09 Mar 2022 12:54:18 +0800</lastBuildDate><atom:link href="https://example.org/categories/machine-learning/index.xml" rel="self" type="application/rss+xml"/><item><title>PyTorch RNN Tutorial</title><link>https://example.org/zh/post/rnn_tutorial/</link><pubDate>Wed, 09 Mar 2022 12:54:18 +0800</pubDate><guid>https://example.org/zh/post/rnn_tutorial/</guid><description>This tutorial will demonstrate how to build and train a simple RNN model with PyTorch.
Concepts What can an RNN do? Given an input sequence $x=[x_1,x_2,\cdots,x_{n}]$, an RNN can generate a corresponding output sequence $\hat y=[\hat y_1,\hat y_2,\cdots,\hat y_{n}]$ successively. The strength of RNN is that it can &amp;ldquo;remember&amp;rdquo; its previosly seen input elements. When calculating $\hat y_i$, the model can access not only $x_i$ but also the information from $x_0$ to $x_{i-1}$, via its hidden state, $h_{i-1}$.</description></item><item><title>NNNode</title><link>https://example.org/zh/post/nnnode/</link><pubDate>Wed, 17 Nov 2021 14:22:09 +0800</pubDate><guid>https://example.org/zh/post/nnnode/</guid><description>做NNNode的動機是我常常在用 Jupyter notebook 和 Pytorch train 神經網路的時候覺得很麻煩</description></item></channel></rss>